{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:45:34.957963Z",
     "start_time": "2025-09-22T19:45:34.954392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from jupyter_core.version import parts\n",
    "\n",
    "OUTPUT_BASE_DIR = \"./output\"\n",
    "DATA_DIR = \"./data\"\n",
    "SAMPLE_IMAGES_PER_GROUP = 20\n",
    "SEED = 42\n",
    "IMAGE_EXTS = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}"
   ],
   "id": "cc5192b75577af0e",
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:45:35.311713Z",
     "start_time": "2025-09-22T19:45:35.307935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import argparse\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "import random\n",
    "import csv\n",
    "import json\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import imagehash\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "id": "3334d7b1e4aaffcd",
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:45:35.738041Z",
     "start_time": "2025-09-22T19:45:35.734447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_images(root_dir):\n",
    "    root = Path(root_dir)\n",
    "    items = []\n",
    "    for p in root.rglob('*'):\n",
    "        if p.suffix.lower() in IMAGE_EXTS:\n",
    "            items.append(p)\n",
    "    return sorted(items)"
   ],
   "id": "5510ee98056d591b",
   "outputs": [],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:45:36.113839Z",
     "start_time": "2025-09-22T19:45:36.110141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def infer_labels_from_path(path: Path, root_dir: Path):\n",
    "    # Get relative path from root directory\n",
    "    rel = path.relative_to(root_dir)\n",
    "\n",
    "    # The folder name we need is the immediate parent directory\n",
    "    folder_name = rel.parent.name  # This gets \"Shelled Healthy Multiple Tamarind\"\n",
    "\n",
    "    # Convert to lowercase for case-insensitive matching\n",
    "    folder_lower = folder_name.lower()\n",
    "\n",
    "    # Extract class (healthy/unhealthy)\n",
    "    if 'unhealthy' in folder_lower or 'diseased' in folder_lower or 'sick' in folder_lower:\n",
    "        cls = 'unhealthy'\n",
    "    elif 'healthy' in folder_lower:\n",
    "        cls = 'healthy'\n",
    "    else:\n",
    "        cls = 'unknown'\n",
    "\n",
    "    # Extract domain (shelled/unshelled)\n",
    "    if 'unshelled' in folder_lower:\n",
    "        domain = 'unshelled'\n",
    "    elif 'shelled' in folder_lower:\n",
    "        domain = 'shelled'\n",
    "    else:\n",
    "        domain = 'mixed'\n",
    "\n",
    "    # Extract multiplicity (single/multiple)\n",
    "    if 'single' in folder_lower:\n",
    "        multiplicity = 'single'\n",
    "    elif 'multiple' in folder_lower:\n",
    "        multiplicity = 'multiple'\n",
    "    else:\n",
    "        multiplicity = 'unknown'\n",
    "\n",
    "    return cls, domain, multiplicity, folder_name"
   ],
   "id": "388f41243a6c205b",
   "outputs": [],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:45:36.448326Z",
     "start_time": "2025-09-22T19:45:36.444375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def is_image_valid(path):\n",
    "    try:\n",
    "        with Image.open(path) as im:\n",
    "            im.verify()  # verify does not load full image in memory\n",
    "        # Reopen to get size safely\n",
    "        with Image.open(path) as im:\n",
    "            im.convert('RGB')\n",
    "        return True, None\n",
    "    except UnidentifiedImageError as e:\n",
    "        return False, f\"UnidentifiedImageError: {e}\"\n",
    "    except Exception as e:\n",
    "        return False, str(e)"
   ],
   "id": "7de5760ed81109",
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:45:36.741708Z",
     "start_time": "2025-09-22T19:45:36.738400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_phash(path, hash_size=16):\n",
    "    try:\n",
    "        with Image.open(path) as im:\n",
    "            ph = imagehash.phash(im, hash_size=hash_size)\n",
    "        return str(ph)\n",
    "    except Exception:\n",
    "        return None"
   ],
   "id": "6eaafefe753ffa30",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:45:37.420877Z",
     "start_time": "2025-09-22T19:45:37.417218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "random.seed(SEED)\n",
    "out = Path(OUTPUT_BASE_DIR)\n",
    "out.mkdir(parents=True, exist_ok=True)\n",
    "data_dir = Path(DATA_DIR)"
   ],
   "id": "7bdc29f8049fca59",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:45:38.015377Z",
     "start_time": "2025-09-22T19:45:37.932489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Finding images...\")\n",
    "images = find_images(data_dir)\n",
    "print(f\"Found {len(images)} images.\")"
   ],
   "id": "a96f923f1ff277cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding images...\n",
      "Found 8432 images.\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:46:21.083853Z",
     "start_time": "2025-09-22T19:45:38.541243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "records = []\n",
    "invalid = []\n",
    "counts = Counter()\n",
    "domain_counts = Counter()\n",
    "size_counts = Counter()\n",
    "phash_map = defaultdict(list)\n",
    "\n",
    "for p in tqdm(images, desc=\"Scanning images\"):\n",
    "    # print(\"Processing\", p)\n",
    "    # print(\"type >>> \", type(p))\n",
    "    valid, err = is_image_valid(p)\n",
    "    if not valid:\n",
    "        invalid.append({'path': str(p), 'error': err})\n",
    "        continue\n",
    "    cls, domain, multiplicity, folder = infer_labels_from_path(p, data_dir)\n",
    "    # open to get size\n",
    "    try:\n",
    "        with Image.open(p) as im:\n",
    "            w,h = im.size\n",
    "    except Exception as e:\n",
    "        invalid.append({'path': str(p), 'error': f\"open_error:{e}\"})\n",
    "        continue\n",
    "    counts[cls] += 1\n",
    "    domain_counts[domain] += 1\n",
    "    size_counts[(w,h)] += 1\n",
    "    ph = compute_phash(p)\n",
    "    if ph is not None:\n",
    "        phash_map[ph].append(str(p))\n",
    "    records.append({\n",
    "        'path': str(p),\n",
    "        'class': cls,\n",
    "        'domain': domain,\n",
    "        'multiplicity': multiplicity,\n",
    "        'folder': folder,\n",
    "        'width': w,\n",
    "        'height': h,\n",
    "        'phash': ph\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame.from_records(records)\n",
    "print(\"Summary counts:\")\n",
    "print(counts)\n",
    "df.to_csv(out / 'tamarind_metadata.csv', index=False)\n",
    "with open(out / 'invalid_images.json', 'w') as f:\n",
    "    json.dump(invalid, f, indent=2)"
   ],
   "id": "31339e6771d0d9fa",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning images: 100%|██████████| 8432/8432 [00:42<00:00, 198.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary counts:\n",
      "Counter({'healthy': 6408, 'unhealthy': 2024})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:55:28.054082Z",
     "start_time": "2025-09-22T19:55:27.986227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# class distribution bar plot\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=list(counts.keys()), y=list(counts.values()))\n",
    "plt.title('Image counts per class')\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('class')\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig(out / 'class_distribution.png', dpi=150)\n",
    "plt.close()"
   ],
   "id": "779cfce034679a13",
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "864d183d6e7f803e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:55:29.911824Z",
     "start_time": "2025-09-22T19:55:29.846684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# domain distribution\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=list(domain_counts.keys()), y=list(domain_counts.values()))\n",
    "plt.title('Image counts per domain (inferred)')\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('domain')\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig(out / 'domain_distribution.png', dpi=150)\n",
    "plt.close()"
   ],
   "id": "8404380bee6862f7",
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:55:31.626918Z",
     "start_time": "2025-09-22T19:55:31.565874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# image size distribution (top N)\n",
    "sizes_sorted = sorted(size_counts.items(), key=lambda x: -x[1])[:10]\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,5))\n",
    "labels = [f\"{w}x{h}\" for (w,h),c in sizes_sorted]\n",
    "vals = [c for (k,c) in sizes_sorted]\n",
    "sns.barplot(x=labels, y=vals, ax=ax)\n",
    "ax.set_title('Top image sizes')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig(out / 'image_sizes_top10.png', dpi=150)\n",
    "plt.close()"
   ],
   "id": "13ffb5edd4f9fa9c",
   "outputs": [],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:46:34.220601Z",
     "start_time": "2025-09-22T19:46:34.212964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# duplicate detection via phash: groups with >1 entry are potential duplicates\n",
    "dup_groups = {k:v for k,v in phash_map.items() if len(v) > 1}\n",
    "with open(out / 'duplicate_groups.json', 'w') as f:\n",
    "    json.dump(dup_groups, f, indent=2)"
   ],
   "id": "422fb4a406cc9eec",
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:46:37.013837Z",
     "start_time": "2025-09-22T19:46:35.111312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sample images per (class, domain) for quick visual inspection\n",
    "grouped = df.groupby(['class','domain'])\n",
    "sample_dir = out / 'samples'\n",
    "sample_dir.mkdir(exist_ok=True)\n",
    "sample_index = []\n",
    "for (cls, dom), g in grouped:\n",
    "    g2 = g.sample(min(len(g), SAMPLE_IMAGES_PER_GROUP), random_state=SEED)\n",
    "    fig, axes = plt.subplots(1, len(g2), figsize=(len(g2)*3,3))\n",
    "    if len(g2)==1:\n",
    "        axes = [axes]\n",
    "    for ax, (_, row) in zip(axes, g2.iterrows()):\n",
    "        try:\n",
    "            img = Image.open(row['path']).convert('RGB')\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "        except Exception as e:\n",
    "            ax.text(0.5,0.5,f\"err:{e}\",ha='center')\n",
    "    title = f\"{cls} | {dom} | n={len(g)}\"\n",
    "    fig.suptitle(title)\n",
    "    fname = f\"sample_{cls}_{dom}.png\".replace(' ','_')\n",
    "    fig.savefig(sample_dir / fname, dpi=150, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    sample_index.append({'class': cls, 'domain': dom, 'count': len(g), 'sample_image': str(sample_dir / fname)})\n",
    "\n",
    "pd.DataFrame(sample_index).to_csv(out / 'samples_index.csv', index=False)\n",
    "\n",
    "# Save a small CSV list of items for further experiments and stratified split\n",
    "df['combined_label'] = df['class'].astype(str) + '|' + df['domain'].astype(str)\n",
    "df.to_csv(out / 'tamarind_metadata_full.csv', index=False)"
   ],
   "id": "6c8c04cb8095fdaf",
   "outputs": [],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:46:38.932813Z",
     "start_time": "2025-09-22T19:46:38.875828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Stratified train/val/test split (70/15/15)\n",
    "items = df.to_dict('records')\n",
    "labels = [r['combined_label'] for r in items]\n",
    "train, temp = train_test_split(items, stratify=labels, test_size=0.30, random_state=SEED)\n",
    "temp_labels = [r['combined_label'] for r in temp]\n",
    "val, test = train_test_split(temp, stratify=temp_labels, test_size=0.5, random_state=SEED)\n",
    "pd.DataFrame(train).to_csv(out / 'split_train.csv', index=False)\n",
    "pd.DataFrame(val).to_csv(out / 'split_val.csv', index=False)\n",
    "pd.DataFrame(test).to_csv(out / 'split_test.csv', index=False)\n",
    "print(\"Saved metadata and splits to:\", out)"
   ],
   "id": "52b310336be0440e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved metadata and splits to: output\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:46:40.285040Z",
     "start_time": "2025-09-22T19:46:40.280362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Quick metrics summary file\n",
    "summary = {\n",
    "    'total_images': len(records),\n",
    "    'invalid_images': len(invalid),\n",
    "    'class_counts': dict(counts),\n",
    "    'domain_counts': dict(domain_counts),\n",
    "    'duplicate_groups_count': len(dup_groups)\n",
    "}\n",
    "with open(out / 'summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print(\"EDA complete. Check the output folder for images and CSVs.\")"
   ],
   "id": "4030a1c0548796a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDA complete. Check the output folder for images and CSVs.\n"
     ]
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "78c6ee51a3da265f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
